{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c75feb4b-8824-4cbe-a769-d15dfe0435e4",
      "metadata": {
        "id": "c75feb4b-8824-4cbe-a769-d15dfe0435e4",
        "outputId": "6e4f661d-572d-40fd-eabc-71e296c8c80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nAlso known as Inception v1.\\nInceptionNet are family of Networks, that are based on Inception Module.\\nThe developers of the InceptionNet were the first to focus on increasing the width and the\\ndepth of the model simultaneously to attain better accuracy while keeping the computing\\nresources constant.\\n\\nThe InceptionNet architecture focusses on parallel processing and 'extraction of various feature maps\\nconcurrently'.\\n\\nInception Module:\\nThe ideology behind the Inception module was that neurons that extract features together should learn together.\\n  ~ Hebbian's Principle\\nThe architecture does not follow Sequential model approach where every operation such\\nas pooling or convolution is performed one after the other.\\n\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "Also known as Inception v1.\n",
        "InceptionNet are family of Networks, that are based on Inception Module.\n",
        "The developers of the InceptionNet were the first to focus on increasing the width and the\n",
        "depth of the model simultaneously to attain better accuracy while keeping the computing\n",
        "resources constant.\n",
        "\n",
        "The InceptionNet architecture focusses on parallel processing and 'extraction of various feature maps\n",
        "concurrently'.\n",
        "\n",
        "Inception Module:\n",
        "The ideology behind the Inception module was that neurons that extract features together should learn together.\n",
        "  ~ Hebbian's Principle\n",
        "The architecture does not follow Sequential model approach where every operation such\n",
        "as pooling or convolution is performed one after the other.\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "FmmRfyvX7tUj"
      },
      "id": "FmmRfyvX7tUj",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset here"
      ],
      "metadata": {
        "id": "JefsNsH2wR1m"
      },
      "id": "JefsNsH2wR1m",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, k, s, p):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=k, stride=s, padding=p),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "XIxQvZ97wBiX"
      },
      "id": "XIxQvZ97wBiX",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReduceConvBlock(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels1, out_channels2, k, p):\n",
        "    super(ReduceConvBlock, self).__init__()\n",
        "    self.redConv = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels1, kernel_size=1, stride = 1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(in_channels=out_channels1, out_channels=out_channels2, kernel_size=k, stride=1, padding=p),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.redConv(x)"
      ],
      "metadata": {
        "id": "gkeZwep-x-Nv"
      },
      "id": "gkeZwep-x-Nv",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionModule(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_1x1, out_interm_3x3, out_3x3, out_interm_5x5, out_5x5, out_pool_proj):\n",
        "    super(InceptionModule, self).__init__()\n",
        "    self.conv1 = ConvBlock(in_channels=in_channels, out_channels=out_1x1, k=1, s=1, p=0)\n",
        "    self.conv2 = ReduceConvBlock(in_channels=in_channels, out_channels1=out_interm_3x3, out_channels2=out_3x3, k=3, p=1)\n",
        "    self.conv3 = ReduceConvBlock(in_channels=in_channels, out_channels1=out_interm_5x5, out_channels2=out_5x5, k=5, p=2)\n",
        "\n",
        "    self.pool_proj = torch.nn.Sequential(\n",
        "        torch.nn.MaxPool2d(kernel_size=3, stride=1),\n",
        "        torch.nn.Conv2d(in_channels=in_channels, out_channels=out_pool_proj, kernel_size=1, stride=1),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.conv1(x)\n",
        "    out2 = self.conv2(x)\n",
        "    out3 = self.conv3(x)\n",
        "    out4 = self.pool_proj(x)\n",
        "\n",
        "    return torch.cat([out1, out2, out3, out4], dim=1) # dim=0 : cat along rows, dim=1 : cat along cols"
      ],
      "metadata": {
        "id": "4l5a8poP8Lmr"
      },
      "id": "4l5a8poP8Lmr",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AuxClassifier(torch.nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super(AuxClassifier, self).__init__()\n",
        "    self.avgpool = torch.nn.AvgPool2d(kernel_size=5, stride=3)\n",
        "    self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=128, kernel_size=1)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.fc = torch.nn.Linear(4*4*128, 1024)\n",
        "    self.dropout = torch.nn.Dropout(p=0.7)\n",
        "    self.classifier = nn.Linear(1024, num_classes)\n",
        "\n",
        "  def forward(self, inp):\n",
        "    N = inp.shape[0]\n",
        "    x = self.avgpool(inp)\n",
        "    x = self.conv(x)\n",
        "    x = self.relu(x)\n",
        "    x = x.reshape(N, -1)\n",
        "    x = self.fc(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "IZs22MhYLPm-"
      },
      "id": "IZs22MhYLPm-",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(torch.nn.Module):\n",
        "  def __init__(self, in_channels = 3, num_class=1000):\n",
        "    super(GoogleNet, self).__init__()\n",
        "    self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64, k=7, s=2, p=1)\n",
        "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "\n",
        "    self.conv2 = torch.nn.Sequential(\n",
        "        ConvBlock(in_channels = 64, out_channels = 64, k = 1, s=1, p=0),\n",
        "        ConvBlock(in_channels=64, out_channels = 192, k=3, s=1, p=1)\n",
        "    )\n",
        "\n",
        "\n",
        "    self.inception_3a = InceptionModule(in_channels=192, out_1x1=64, out_interm_3x3=96, out_3x3=128, out_interm_5x5=16, out_5x5=32, out_pool_proj=32)\n",
        "    self.inception_3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
        "    # a MaxPool2d here\n",
        "    self.inception_4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n",
        "    self.inception_4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n",
        "    self.inception_4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n",
        "    self.inception_4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n",
        "    self.inception_4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
        "    # a MaxPool2d here\n",
        "    self.inception_5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
        "    self.inception_5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
        "    # a AvgPool2d here\n",
        "\n",
        "    self.aux_classifier1 = AuxClassifier(512, num_class)\n",
        "    self.aux_classifier2 = AuxClassifier(528, num_class)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.4),\n",
        "        nn.Linear(1024 * 7 * 7, num_class)\n",
        "    )\n",
        "\n",
        "  def forward(self, input_img):\n",
        "    N = input_img.shape[0]\n",
        "    x = self.conv1(input_img)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.inception_3a(x)\n",
        "    x = self.inception_3b(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.inception_4a(x)\n",
        "    out1 = self.aux_classifier1(x)\n",
        "    x = self.inception_4b(x)\n",
        "    x = self.inception_4c(x)\n",
        "    x = self.inception_4d(x)\n",
        "    out2 = self.aux_classifier2(x)\n",
        "    x = self.inception_4e(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.inception_5a(x)\n",
        "    x = self.inception_5b(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.reshape(N, -1)\n",
        "    x = self.classifier(x)\n",
        "    if self.training == True:\n",
        "        return [x, out1, out2]\n",
        "    else:\n",
        "        return x"
      ],
      "metadata": {
        "id": "tUgtzSI61y6K"
      },
      "id": "tUgtzSI61y6K",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Temporary define data and target\n",
        "    batch_size = 5\n",
        "    x = torch.randn((batch_size, 3, 224, 224))\n",
        "    y = torch.randint(0,1000, (batch_size,))\n",
        "    num_classes = 1000\n",
        "\n",
        "    # Add to graph in tensorboard\n",
        "    writer = SummaryWriter(log_dir='logs/googlenet')\n",
        "    m = MyGoogleNet()\n",
        "    # print(m)\n",
        "    # we have x,o1,o2 = m(x)\n",
        "    # m(x)[0] means x; m(x)[1] means o1; m(x)[2] means o2\n",
        "    # o1 and o2 are output from auxclassifier\n",
        "    print(m(x)[0].shape)\n",
        "    m.eval()\n",
        "    print(m.training)\n",
        "    writer.add_graph(m, x)\n",
        "    writer.close()\n",
        "\n",
        "    # Notice here! When you going to train your network\n",
        "    # Put these loss value into train step of your model\n",
        "\n",
        "    m.train()\n",
        "\n",
        "    \"\"\"\n",
        "    m.train() acctivates layers like Dropout() and BatchNorm(). without calling .train() these layers won't\n",
        "    fired! modules like nn.Dropout check the model's mode internally using self.training\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    loss1 = nn.CrossEntropyLoss()\n",
        "    loss2 = nn.CrossEntropyLoss()\n",
        "    discount = 0.3\n",
        "\n",
        "    o,o1,o2 = m(x)\n",
        "\n",
        "    total_loss = loss(o,y) + discount*(loss1(o1,y) + loss2(o2,y))\n",
        "    print(total_loss)\n",
        "\n",
        "    # And while inferencing the model, set the model into\n",
        "    # model.eval() mode\n",
        "    m.eval()"
      ],
      "metadata": {
        "id": "_mGG6Y5L79PL"
      },
      "id": "_mGG6Y5L79PL",
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}